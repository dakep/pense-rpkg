<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Estimating predictive models • pense</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Estimating predictive models">
<meta property="og:description" content="pense">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">pense</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">2.0.2.200</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/computing_adapense.html">Estimating predictive models</a>
    </li>
    <li>
      <a href="../articles/lambda_grids.html">Controlling the grid of penalization levels</a>
    </li>
    <li>
      <a href="../articles/migration_guide.html">Migrating from pense version 1.x to 2.x</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/dakep/pense-rpkg/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><link href="computing_adapense_files/anchor-sections-1.0/anchor-sections.css" rel="stylesheet">
<script src="computing_adapense_files/anchor-sections-1.0/anchor-sections.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Estimating predictive models</h1>
                        <h4 class="author">David Kepplinger</h4>
            
            <h4 class="date">2020-11-07</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/dakep/pense-rpkg/blob/master/vignettes/computing_adapense.Rmd"><code>vignettes/computing_adapense.Rmd</code></a></small>
      <div class="hidden name"><code>computing_adapense.Rmd</code></div>

    </div>

    
    
<p>In this guide we will estimate predictive models by means of robust adaptive PENSE estimates for high-dimensional linear regression. These estimates can tolerate up to 50% of contamination, i.e., the adaptive PENSE estimates are reliable even if up to half the observations in the data set contain anomalous values. Compute adaptive PENSE estimates is implemented in the function <code><a href="../reference/pense_cv.html">adapense_cv()</a></code> in the pense package.</p>
<p>While the following guide computes adaptive PENSE estimates, everything also applies to other estimates implemented in the pense package: non-adaptive PENSE estimates and regularized M-estimates. Non-adaptive PENSE estimates (computed by <code><a href="../reference/pense_cv.html">pense_cv()</a></code>) are typically better at identifying all relevant predictors than adaptive PENSE. However, this comes at the price of often including a large number of irrelevant predictors as well. Regularized M-estimates (computed by <code><a href="../reference/pensem_cv.html">pensem_cv()</a></code>) can be more accurate than either PENSE or adaptive PENSE estimates, but may be unreliable in presence of highly detrimental contamination.</p>
<div id="computing-adaptive-pense-estimates" class="section level1">
<h1 class="hasAnchor">
<a href="#computing-adaptive-pense-estimates" class="anchor"></a>Computing adaptive PENSE estimates</h1>
<p>First we need to load the pense package:</p>
<div class="sourceCode" id="cb1"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="kw"><a href="https://dakep.github.io/pense-rpkg">pense</a></span>)
<span class="co">#&gt; Loading required package: Matrix</span>
</pre></div>
<p>Computing robust, regularized estimates for high-dimensional linear regression models can take a long time. Luckily many steps can be done in parallel to save time. If your computer has more than 1 CPU core, you can harness more computing power by creating a cluster of R processes:</p>
<div class="sourceCode" id="cb2"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="kw">parallel</span>)
<span class="co"># If you don't know how many CPU cores are available, first run `detectCores(logical = FALSE)`</span>
<span class="kw">cluster</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/parallel/makeCluster.html">makeCluster</a></span>(<span class="fl">3</span>)
</pre></div>
<p>This guide uses the following simulated data with 50 observations and 40 available predictors. The error distribution is a heavy-tailed <em>t</em>-distribution and only the first 3 predictors are truly relevant for predicting the response <em>y</em>:</p>
<div class="sourceCode" id="cb3"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">1234</span>)
<span class="kw">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/stats/Weibull.html">rweibull</a></span>(<span class="fl">50</span> <span class="op">*</span> <span class="fl">40</span>, <span class="fl">2</span>, <span class="fl">3</span>), ncol = <span class="fl">40</span>)
<span class="kw">y</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">*</span> <span class="kw">x</span>[, <span class="fl">1</span>] <span class="op">-</span> <span class="fl">1.1</span> <span class="op">*</span> <span class="kw">x</span>[, <span class="fl">2</span>] <span class="op">+</span> <span class="fl">1.2</span> <span class="op">*</span> <span class="kw">x</span>[, <span class="fl">3</span>] <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">rt</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(<span class="kw">x</span>), df = <span class="fl">2</span>)
</pre></div>
<p>To make the scenario more realistic, let’s add some contamination to the response value of the first 3 observations and to some predictors:</p>
<div class="sourceCode" id="cb4"><pre class="downlit">
<span class="kw">y</span>[<span class="fl">1</span><span class="op">:</span><span class="fl">3</span>] <span class="op">&lt;-</span> <span class="fl">5</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span>(<span class="kw">x</span>[<span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, ], <span class="fl">1</span>, <span class="kw">max</span>)
<span class="kw">x</span>[<span class="fl">3</span><span class="op">:</span><span class="fl">6</span>, <span class="fl">4</span><span class="op">:</span><span class="fl">6</span>] <span class="op">&lt;-</span> <span class="fl">1.5</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span>(<span class="kw">x</span>) <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span>(<span class="fu"><a href="https://rdrr.io/r/stats/Cauchy.html">rcauchy</a></span>(<span class="fl">4</span> <span class="op">*</span> <span class="fl">3</span>))
</pre></div>
<div id="step-1-computing-the-estimates" class="section level2">
<h2 class="hasAnchor">
<a href="#step-1-computing-the-estimates" class="anchor"></a>Step 1: Computing the estimates</h2>
<p>The first step is to compute adaptive PENSE estimates for a fixed value for hyper-parameter <code>alpha</code> and many different penalization levels (hyper-parameter <code>lambda</code>). The <code><a href="../reference/pense_cv.html">adapense_cv()</a></code> function automatically determines a grid of penalization levels, with parameter <code>nlambda=</code> controlling the number of different penalization levels to be used (default 50). We are going to choose the penalization level which leads to a good balance between prediction accuracy and model size. The pense package can automatically evaluate prediction accuracy of the adaptive PENSE estimates via cross-validation.</p>
<p>In its simplest form, computing adaptive PENSE estimates and estimating their prediction accuracy is done with the code below. Here, prediction accuracy is estimated via 5-fold cross-validation, replicated 3 times:</p>
<div class="sourceCode" id="cb5"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">1234</span>)
<span class="kw">fit_075</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/pense_cv.html">adapense_cv</a></span>(<span class="kw">x</span>, <span class="kw">y</span>, alpha = <span class="fl">0.75</span>, cv_k = <span class="fl">5</span>, cv_repl = <span class="fl">3</span>, cl = <span class="kw">cluster</span>)
</pre></div>
<p>You should always set a seed prior to computing adaptive PENSE or PENSE estimates to ensure reproducibility of the internal cross-validation.</p>
<p>By default, adaptive PENSE estimates are computed with a breakdown point of 25%. This means, the estimates are reliable if up to 25% of observations contain arbitrary contamination. If you suspect that a larger proportion of observations may be affected by contamination, you can increase the breakdown point of the estimates with argument <code>bdp=</code> to up to 50%. Note, however, that a higher breakdown point also leads to less accurate estimates.</p>
</div>
<div id="step-2-assessing-prediction-performance" class="section level2">
<h2 class="hasAnchor">
<a href="#step-2-assessing-prediction-performance" class="anchor"></a>Step 2: Assessing prediction performance</h2>
<p>The <code><a href="https://rdrr.io/r/graphics/plot.default.html">plot()</a></code> function for the object <code>fit_075</code> shows the estimated prediction accuracy for all fitted models.</p>
<div class="sourceCode" id="cb6"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span>(<span class="kw">fit_075</span>)
</pre></div>
<div class="figure">
<img src="computing_adapense_files/figure-html/unnamed-chunk-6-1.png" alt="Estimated prediction accuracy using 3 replications of 5-fold CV." width="672"><p class="caption">
Estimated prediction accuracy using 3 replications of 5-fold CV.
</p>
</div>
<p>The plot shows the estimated scale of the prediction error for all 50 models. The penalization level leading to the best prediction performance is highlighted by a dark blue dot. If more than one CV replication was performed, the plot also shows a light blue dot, marking the most parsimonious model with prediction performance “indistinguishable” from the best model. The plot uses the “one-standard-error” rule, visualized by the dashed horizontal line depicting the the minimum average scale of the prediction error plus 1 standard error of this estimated scale. You can adjust this rule to the “<em>q</em>-standard-error” with <code><a href="https://rdrr.io/r/graphics/plot.default.html">plot(se_mult = q)</a></code>, where <code>q</code> is any positive number.</p>
<p>In our case, the estimated prediction performance is fairly unstable and has large variability. With such unstable estimates of prediction performance it is difficult to reliably select the penalization level. This is not unusual for robust estimators and can be improved by increasing the number of CV replications.</p>
<p>The more CV replications, the more accurate the estimates of prediction accuracy, but the longer the computing time. If we repeat step #1, but with 10 CV replications instead of 3, we get a more stable evaluation of prediction performance:</p>
<div class="sourceCode" id="cb7"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">1234</span>)
<span class="kw">fit_075</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/pense_cv.html">adapense_cv</a></span>(<span class="kw">x</span>, <span class="kw">y</span>, alpha = <span class="fl">0.75</span>, cv_k = <span class="fl">5</span>, cv_repl = <span class="fl">10</span>, cl = <span class="kw">cluster</span>)
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span>(<span class="kw">fit_075</span>)
</pre></div>
<div class="figure">
<img src="computing_adapense_files/figure-html/unnamed-chunk-9-1.png" alt="Estimated prediction accuracy using 10 replications of 5-fold CV." width="672"><p class="caption">
Estimated prediction accuracy using 10 replications of 5-fold CV.
</p>
</div>
<p>With 10 replications, the error bars are still large, a testament of the contamination in the sample, but the general trend of the prediction performance is much clearer. Of course, you could increase the number of CV replications further to get an even smoother plot.</p>
</div>
<div id="step-3-extracting-coefficients" class="section level2">
<h2 class="hasAnchor">
<a href="#step-3-extracting-coefficients" class="anchor"></a>Step 3: Extracting coefficients</h2>
<p>Once we are happy with the stability of the estimated prediction performance, we can extract summary information from the predictive model with</p>
<div class="sourceCode" id="cb8"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="kw">fit_075</span>)
<span class="co">#&gt; Adaptive PENSE fit with prediction performance estimated by 10 replications of </span>
<span class="co">#&gt; 5-fold cross-validation.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; 14 out of 40 predictors have non-zero coefficients:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                 Estimate</span>
<span class="co">#&gt; (Intercept)  1.527069371</span>
<span class="co">#&gt; X1           0.722224241</span>
<span class="co">#&gt; X2          -0.868422718</span>
<span class="co">#&gt; X3           0.794967863</span>
<span class="co">#&gt; X5           0.061834699</span>
<span class="co">#&gt; X12          0.100211936</span>
<span class="co">#&gt; X19         -0.225896936</span>
<span class="co">#&gt; X21          0.304081225</span>
<span class="co">#&gt; X22          0.063632685</span>
<span class="co">#&gt; X26         -0.402350971</span>
<span class="co">#&gt; X29          0.201989891</span>
<span class="co">#&gt; X32         -0.001817195</span>
<span class="co">#&gt; X36         -0.273561877</span>
<span class="co">#&gt; X39         -0.134544249</span>
<span class="co">#&gt; X40         -0.001827169</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Hyper-parameters: lambda=0.05512509, exponent=1</span>
<span class="co">#&gt; Estimated scale of the prediction error: 1.982047</span>
</pre></div>
<p>This model corresponds to the model with smallest scale of the prediction error (the blue dot in the plot above). There are a total of 14 predictors in the model. If you think a sparser model may be more appropriate for your application, you can also apply the <em>q</em>-standard-error rule as in the plots. The default, the one-standard-error rule leads to the following predictive model:</p>
<div class="sourceCode" id="cb9"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="kw">fit_075</span>, lambda = <span class="st">"se"</span>)
<span class="co">#&gt; Adaptive PENSE fit with prediction performance estimated by 10 replications of </span>
<span class="co">#&gt; 5-fold cross-validation.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; 7 out of 40 predictors have non-zero coefficients:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                Estimate</span>
<span class="co">#&gt; (Intercept)  0.22807906</span>
<span class="co">#&gt; X1           0.76580403</span>
<span class="co">#&gt; X2          -0.81598826</span>
<span class="co">#&gt; X3           0.85016587</span>
<span class="co">#&gt; X5           0.02493568</span>
<span class="co">#&gt; X22          0.02658272</span>
<span class="co">#&gt; X29          0.10179342</span>
<span class="co">#&gt; X39         -0.07248717</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Hyper-parameters: lambda=0.1540881, exponent=1</span>
<span class="co">#&gt; Estimated scale of the prediction error: 2.10859</span>
</pre></div>
<p>In this fit, only 7 out of the 40 predictors are relevant, including the 3 truly relevant predictors. But maybe different values for hyper-parameters <code>alpha</code> and <code>exponent</code> lead to even better prediction?</p>
</div>
<div id="step-4-exploring-different-hyper-parameters" class="section level2">
<h2 class="hasAnchor">
<a href="#step-4-exploring-different-hyper-parameters" class="anchor"></a>Step 4: Exploring different hyper-parameters</h2>
<p>The choice for hyper-parameters <code>alpha</code> and <code>exponent</code> (which was kept at its default value of 1) are rather arbitrary. The effects of these two hyper-parameters on the estimates are in general less pronounced than of the penalization level. But you may still want to explore different values for <code>alpha</code> and <code>exponent</code>.</p>
<p>While <code>alpha=0.75</code> is a good value for many applications, <code>alpha=1</code> may also be of interest, particularly in applications where correlation between predictors is not an issue. In applications with high correlation between predictors, lower values of <code>alpha</code> (e.g., <code>alpha=0.5</code>) may lead to more stability in variable selection.</p>
<p>The hyper-parameter <code>exponent</code> generally has an effect on the sparsity of the models. With higher values for <code>exponent</code>, typically only predictors with the largest (in an absolute sense) standardized coefficients will be non-zero. While this helps to screen out many or most of the truly irrelevant, it also risks missing some of the truly relevant predictors.</p>
<p>Let us compute adaptive PENSE estimates for different values of hyper-parameters <code>alpha</code> and <code>exponent</code>. In the code below, this is done by manually iterating two different values for our hyper parameters: <code>alpha=0.75</code> and <code>alpha=1</code> as well as <code>exponent=1</code> and <code>exponent=2</code>. For more values of the hyper-parameters, iterating over all the possible combinations would be easier.</p>
<div class="sourceCode" id="cb10"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">1234</span>)
<span class="kw">fit_075_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/pense_cv.html">adapense_cv</a></span>(<span class="kw">x</span>, <span class="kw">y</span>, alpha = <span class="fl">0.75</span>, exponent = <span class="fl">2</span>, cv_k = <span class="fl">5</span>, cv_repl = <span class="fl">10</span>, cl = <span class="kw">cluster</span>)

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">1234</span>)
<span class="kw">fit_100_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/pense_cv.html">adapense_cv</a></span>(<span class="kw">x</span>, <span class="kw">y</span>, alpha = <span class="fl">1</span>, exponent = <span class="fl">1</span>, cv_k = <span class="fl">5</span>, cv_repl = <span class="fl">10</span>, cl = <span class="kw">cluster</span>)

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">1234</span>)
<span class="kw">fit_100_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/pense_cv.html">adapense_cv</a></span>(<span class="kw">x</span>, <span class="kw">y</span>, alpha = <span class="fl">1</span>, exponent = <span class="fl">2</span>, cv_k = <span class="fl">5</span>, cv_repl = <span class="fl">10</span>, cl = <span class="kw">cluster</span>)
</pre></div>
<p>Note that we set the seed before each call to <code><a href="../reference/pense_cv.html">adapense_cv()</a></code>. This is again to ensure reproducibility of CV, but also to make the estimated prediction performance more comparable across different values of the hyper-parameters.</p>
<p>After checking that the cross-validated prediction performance of the fitted models is smooth enough to reliably select the penalization level, we can compare all the estimates. For this, the package includes the function <code><a href="../reference/prediction_performance.html">prediction_performance()</a></code>, which extracts and prints the prediction performance of all given objects:</p>
<div class="sourceCode" id="cb11"><pre class="downlit">
<span class="fu"><a href="../reference/prediction_performance.html">prediction_performance</a></span>(<span class="kw">fit_075</span>, <span class="kw">fit_075_2</span>, <span class="kw">fit_100_1</span>, <span class="kw">fit_100_2</span>)
<span class="co">#&gt; Prediction performance estimated by cross-validation:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;       Model Estimate Std. Error Predictors exp.</span>
<span class="co">#&gt; 1 fit_075_2 1.864024  0.2022757         14    2</span>
<span class="co">#&gt; 2 fit_100_2 1.864606  0.2010057         14    2</span>
<span class="co">#&gt; 3   fit_075 1.982047  0.1795832         14    1</span>
<span class="co">#&gt; 4 fit_100_1 1.988588  0.1466705         12    1</span>
</pre></div>
<p>Here we see the combination of hyper-parameters <code>alpha=0.75</code> and <code>exponent=1</code> (in object <code>fit_075_2</code>) lead to the best prediction accuracy, but the models are all based on more than 12 predictors. Instead, we can also compare sparser models with almost the same prediction performance:</p>
<div class="sourceCode" id="cb12"><pre class="downlit">
<span class="fu"><a href="../reference/prediction_performance.html">prediction_performance</a></span>(<span class="kw">fit_075</span>, <span class="kw">fit_075_2</span>, <span class="kw">fit_100_1</span>, <span class="kw">fit_100_2</span>, lambda = <span class="st">'se'</span>)
<span class="co">#&gt; Prediction performance estimated by cross-validation:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;       Model Estimate Std. Error Predictors exp.</span>
<span class="co">#&gt; 1 fit_075_2 2.027702  0.2323029          4    2</span>
<span class="co">#&gt; 2 fit_100_2 2.045782  0.2314871          4    2</span>
<span class="co">#&gt; 3 fit_100_1 2.081398  0.2771445          7    1</span>
<span class="co">#&gt; 4   fit_075 2.108590  0.2692151          7    1</span>
</pre></div>
<p>Still, the combination of hyper-parameters <code>alpha=0.75</code> and <code>exponent=1</code> outperforms the others. We can see that the estimated coefficients and estimated relevant predictors are close to the truth:</p>
<div class="sourceCode" id="cb13"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="kw">fit_075_2</span>, lambda = <span class="st">'se'</span>)
<span class="co">#&gt; Adaptive PENSE fit with prediction performance estimated by 10 replications of </span>
<span class="co">#&gt; 5-fold cross-validation.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; 4 out of 40 predictors have non-zero coefficients:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                Estimate</span>
<span class="co">#&gt; (Intercept)  0.42755964</span>
<span class="co">#&gt; X1           0.84993695</span>
<span class="co">#&gt; X2          -0.91559693</span>
<span class="co">#&gt; X3           0.85350171</span>
<span class="co">#&gt; X21          0.02125563</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Hyper-parameters: lambda=0.02962154, exponent=2</span>
<span class="co">#&gt; Estimated scale of the prediction error: 2.027702</span>
</pre></div>
</div>
<div id="using-different-measures-of-prediction-performance" class="section level2">
<h2 class="hasAnchor">
<a href="#using-different-measures-of-prediction-performance" class="anchor"></a>Using different measures of prediction performance</h2>
<p>By default, <code><a href="../reference/pense_cv.html">adapense_cv()</a></code> uses the τ-scale of the prediction errors to assess prediction accuracy. This can be changed by specifying a different metric via <code><a href="../reference/pense_cv.html">adapense_cv(cv_metric=)</a></code>. The package supports also the median absolute prediction error (<code>cv_metric = "mape"</code>) or the classical root mean squared prediction error (<code>cv_metric = "rmspe"</code>). You should, however, not use the RMSPE to evaluate prediction performance in the potential presence of contamination. Robust methods are not designed to predict contaminated observations well and the RMSPE may be artificially inflated by poor prediction of a few contaminated response values. You can also specify your own function which takes as input the vector of prediction errors and returns a single number, measuring the prediction performance. For example, to use the <em>mean</em> absolute prediction error, you would write</p>
<div class="sourceCode" id="cb14"><pre class="downlit">
<span class="kw">mae</span> <span class="op">&lt;-</span> <span class="fu">function</span> (<span class="kw">prediction_errors</span>) {
  <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span>(<span class="kw">prediction_errors</span>))
}

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">1234</span>)
<span class="kw">fit_075_mae</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/pense_cv.html">adapense_cv</a></span>(<span class="kw">x</span>, <span class="kw">y</span>, alpha = <span class="fl">0.75</span>, cv_k = <span class="fl">5</span>, cv_repl = <span class="fl">5</span>, cl = <span class="kw">cluster</span>, cv_metric = <span class="kw">mae</span>)
</pre></div>
<p>A matrix with estimates of the prediction performance are accessible as slot <code>$cv_replications</code> in the object returned by <code><a href="../reference/pense_cv.html">adapense_cv()</a></code>. The rows correspond to the different penalization levels, and columns correspond to the individual CV replications.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by David Kepplinger, Matías Salibián-Barrera, Gabriela Cohen Freue.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
