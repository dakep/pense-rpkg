% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/coef-methods.R
\name{coef.pense_cvfit}
\alias{coef.pense_cvfit}
\title{Extract Coefficient Estimates}
\usage{
\method{coef}{pense_cvfit}(
  object,
  lambda = "min",
  alpha,
  se_mult = 1,
  sparse = NULL,
  standardized = FALSE,
  exact = deprecated(),
  correction = deprecated(),
  ...
)
}
\arguments{
\item{object}{PENSE with cross-validated hyper-parameters to extract coefficients from.}

\item{lambda}{either a string specifying which penalty level to use
(\code{"min"}, \code{"se"}, \verb{"\{x\}-se}")
or a single numeric value of the penalty parameter. See details.}

\item{alpha}{Either a single number or missing.
If given, only fits with the given \code{alpha} value are considered.
If \code{lambda} is a numeric value and \code{object} was fit with multiple \code{alpha}
values, the parameter \code{alpha} must not be missing.}

\item{se_mult}{If \code{lambda = "se"}, the multiple of standard errors to tolerate.}

\item{sparse}{should coefficients be returned as sparse or dense vectors?
Defaults to the sparsity setting of the given \code{object}.
Can also be set to \code{sparse = 'matrix'}, in which case a sparse matrix
is returned instead of a sparse vector.}

\item{standardized}{return the standardized coefficients.}

\item{exact, correction}{defunct.}

\item{...}{currently not used.}
}
\value{
either a numeric vector or a sparse vector of type
\link[Matrix:sparseVector-class]{dsparseVector}
of size \eqn{p + 1}, depending on the \code{sparse} argument.
Note: prior to version 2.0.0 sparse coefficients were returned as sparse matrix of
type \emph{dgCMatrix}.
To get a sparse matrix as in previous versions, use \code{sparse = 'matrix'}.
}
\description{
Extract coefficients from an adaptive PENSE (or LS-EN) regularization path with hyper-parameters
chosen by cross-validation.
}
\details{
If \code{lambda = "se"} and \code{object} contains fitted estimates for every penalization level in
the sequence, extract the coefficients of the most parsimonious model with prediction
performance statistically indistinguishable from the best model.
This is determined to be the model with prediction performance within \code{se_mult * cv_se}
from the best model.
The string in \code{lambda} can also directly specify the multiplier by setting \code{lambda = "{x}-se"},
where \code{{x}} is any (positive) number.
}
\examples{
# Compute the PENSE regularization path for Freeny's revenue data
# (see ?freeny)
data(freeny)
x <- as.matrix(freeny[ , 2:5])

regpath <- pense(x, freeny$y, alpha = 0.5)
plot(regpath)

# Extract the coefficients at a certain penalization level
coef(regpath, lambda = regpath$lambda[40])

# What penalization level leads to good prediction performance?
cv_results <- pense_cv(x, freeny$y, alpha = 0.5, cv_repl = 2,
                       cv_k = 4)
plot(cv_results, se_mult = 1)

# Extract the coefficients at the penalization level with
# smallest prediction error ...
coef(cv_results)
# ... or at the penalization level with prediction error
# statistically indistinguishable from the minimum.
coef(cv_results, lambda = 'se')
}
\seealso{
Other functions for extracting components: 
\code{\link{coef.pense_fit}()},
\code{\link{predict.pense_cvfit}()},
\code{\link{predict.pense_fit}()},
\code{\link{residuals.pense_cvfit}()},
\code{\link{residuals.pense_fit}()}
}
\concept{functions for extracting components}
